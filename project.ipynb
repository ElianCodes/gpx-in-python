{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with GPX-files in Python\n",
    "\n",
    "By using numpy, pandas, SciKit-learn & gpxpy\n",
    "\n",
    "a project by [Elian Van Cutsem](<http://www.elianvancutsem.com>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## relative path to data-files\n",
    "\n",
    "in the cell below you can define your own relative path to a folder with gpx files. This is the folder included in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = './sampleData/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test data and representative parts\n",
    "\n",
    "In the variables below you can choose either all the files in your gpx-file folder should be used or just a preview with a few files. The latter is way more performant but less precise. You can edit how many files should be used and choose to ignore the test data. These variables are used in further cells as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "maxFilesToUse = 100\n",
    "useTestData = True\n",
    "\n",
    "# hide futureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports\n",
    "\n",
    "before you run this cell, make sure you have installed the gpxpy library in anaconda by running `pip install gpxpy` in the anaconda prompt. The other libraries mentioned below are automatically installed with [anaconda](<https://www.anaconda.com/>)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from datetime import timedelta\n",
    "from matplotlib.pyplot import figure\n",
    "from os import walk\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from copy import copy\n",
    "\n",
    "import os\n",
    "import statistics\n",
    "import gpxpy.gpx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reading Data and visualising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "\n",
    "To edit and manipulate the given data, we first have to analyze how a gpx file is structured and can be used as a object in Python. In the first step below, we print out the files from the folder with the given gpx files. The code should be independent from any type of gpx file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data from gpx files\n",
    "\n",
    "The code below searches all files with a .gpx extension and puts them in a list. This list will later be used to effectively read data from the file with the name from the list. This step also makes use of the test data if you configured it. The test data variables will limit the number of files read by the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpxFileList = []\n",
    "numberOfFiles = 1\n",
    "numberOfFilesInDirectory = 0\n",
    "\n",
    "for (path, names, filenames) in walk(dataPath):\n",
    "    numberOfFilesInDirectory = len(filenames)\n",
    "    \n",
    "    for file in names:\n",
    "        if file.endswith('.gpx'):\n",
    "            if numberOfFiles >= maxFilesToUse and useTestData:\n",
    "                break\n",
    "            else:\n",
    "                gpxFileList.append(file)\n",
    "            numberOfFiles += 1\n",
    "            \n",
    "print(f\"number of .gpx files: {len(gpxFileList)}/{numberOfFiles}\")\n",
    "print(\"total number of files in directory:\", numberOfFilesInDirectory)\n",
    "print(\"total number of files looked at:\", numberOfFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming read data to a dataframe\n",
    "\n",
    "Now that we know how many files we can use and we have a variable list `gpxFileList` with all the filenames, every file in that list can be opened and transformed to a gpx usable object in Python. Now that we have to read and calculate the object. It's a perfect time to calculate some basic features to select usable and trustworthy files on. We will filter all unrepresentative data and files out so we only keep good files for further use. Since a gps is never 100% accurate, some files become completely unusable and are better ignored than used.\n",
    "Since this step is quite intensive, it can take some time to calculate all the data. If it takes too long, you can limit the files in the variables initialized in the first few steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_heartbeat(gpx):\n",
    "    found_hr = 0\n",
    "    for extensions in gpx.points[0].extensions:\n",
    "        for extension in extensions:\n",
    "            if extension.tag[-2:] == 'hr':\n",
    "                found_hr = 1\n",
    "                break\n",
    "    return found_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData = pd.DataFrame()\n",
    "\n",
    "for file in gpxFileList:\n",
    "    try:\n",
    "        gpx_file = open(dataPath + file, 'r')\n",
    "        gpx = gpxpy.parse(gpx_file)\n",
    "        route = gpx.tracks[0]\n",
    "        \n",
    "        rawData = rawData.append({\n",
    "            \"filename\": file,\n",
    "            \"file_id\": file.split('_')[0],\n",
    "            \"creator\": gpx.creator,\n",
    "            \"name\": route.name,\n",
    "            \"date\": route.get_time_bounds().start_time,\n",
    "            \"total distance\": route.length_3d(),\n",
    "            \"total time\": route.get_duration(),\n",
    "            \"nr of points\": route.get_points_no(),\n",
    "            \"top speed\": route.get_moving_data().max_speed,\n",
    "            \"has elevation\": route.has_elevations(),\n",
    "            \"has heartbeat\":  has_heartbeat(route.segments[0]),\n",
    "            \"type\": file.split('_')[1][:-4],\n",
    "        }, ignore_index=True)\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "rawData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filtering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering of data\n",
    "\n",
    "Here we're looping the results of the previous cell and we're going to check if they are usable or not. The variables that define if they're usable are shown in the cell below. All unusable files are removed from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSpeed = 200\n",
    "maxTime = timedelta(hours=24)\n",
    "minTime = timedelta(minutes=5)\n",
    "minNumberOfPoints = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredData = pd.DataFrame()\n",
    "\n",
    "for index, row in rawData.iterrows():\n",
    "    error = 0\n",
    "    try:\n",
    "        if row['total time'] > maxTime.total_seconds():\n",
    "            error = 1\n",
    "        elif row['total time'] < minTime.total_seconds():\n",
    "            error = 1\n",
    "        elif row['number of points'] < minNumberOfPoints:\n",
    "            error = 1\n",
    "        elif row['top speed'] > maxSpeed:\n",
    "            gpx_file = open(dataPath + row['filename'], 'r')\n",
    "            gpx = gpxpy.parse(gpx_file)\n",
    "            removedPoints = 0\n",
    "\n",
    "            try:\n",
    "                while gpx.get_moving_data().max_speed > maxSpeed:\n",
    "                    points = gpx.tracks[0].segments[0].points\n",
    "                    for i in range(0, len(points)-1):\n",
    "                        punt = points[i-removedPoints]\n",
    "                        nextPoint = points[i+1-removedPoints]\n",
    "                        speed = punt.speed_between(nextPoint)\n",
    "                        if speed > maxSpeed:\n",
    "                            removedPoints += 1\n",
    "                            del gpx.tracks[0].segments[0].points[i-removedPoints]\n",
    "            except:\n",
    "                error = 1\n",
    "    except:\n",
    "        error = 1\n",
    "        \n",
    "    if error == 0:\n",
    "        filteredData = filteredData.append(row)\n",
    "\n",
    "print('number of removed files:', str(len([name for name in os.listdir(dataPath)])-len(filteredData)))\n",
    "\n",
    "filteredData = filteredData.reset_index()\n",
    "\n",
    "filteredData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data as a csv-file\n",
    "\n",
    "Since it can take a lot of time to calculate all files, we make a csv file with all info we calculated so we can reuse all data without recalculating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredData.to_csv('filesTest.csv') if useTestData else filteredData.to_csv('files.csv')\n",
    "print('Saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at individual files\n",
    "\n",
    "Now that only representative data is left, we can take a look at how a file is structured and what is stored in a GPX-file. We can translate all this info to charts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Reading the data from the previous made CSV-file\n",
    "\n",
    "Here we read all data from the CSV-file that was previously created. This step can be skipped if all data was calculated on the same kernel. It never does harm to execute the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filteredData = pd.read_csv('filesTest.csv') if useTestData else pd.read_csv('files.csv')\n",
    "print('Read all data!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of a random file\n",
    "\n",
    "In the cell below we select a random file from the filtered data. Then we take a look at what info is stored the GPX object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rand = random.randrange(len(filteredData))\n",
    "file = filteredData[\"filename\"][rand]\n",
    "gpx_file = open(dataPath + file, 'r')\n",
    "gpx = gpxpy.parse(gpx_file)\n",
    "print(gpx.to_xml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"File: \" +  filteredData[\"filename\"][rand])\n",
    "print(\"Creator of the track: \" + gpx.creator)\n",
    "\n",
    "for track in gpx.tracks:\n",
    "    print(\"track name: \" + track.name)\n",
    "    print(\"number of points in the segment: \", gpx.get_points_no())\n",
    "    print(\"length of the route \" + str(round(gpx.length_2d() / 1000,2)) + 'km')\n",
    "    print(\"first point in the segment: \", gpx.get_time_bounds().start_time)\n",
    "    print(\"last point in the segment: \",  gpx.get_time_bounds().end_time)\n",
    "    print(\"total time in seconds: \", track.get_duration())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### charts we can create by using a random file\n",
    "\n",
    "If we have access to all points in a file, we can construct a chart which will match the route in the GPX object. Some files also have elevation data, speed data and heart rate data. If we have these, they also can be translated to a chart. (but not all files have these)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = []\n",
    "lat = []\n",
    "height = []\n",
    "speed = []\n",
    "hr = []\n",
    "\n",
    "print(\"File: \" + file)\n",
    "points = gpx.tracks[0].segments[0].points\n",
    "for point in points:\n",
    "    lon.append(float(point.longitude))\n",
    "    lat.append(float(point.latitude))\n",
    "    if point.elevation is not None:\n",
    "        height.append(point.elevation)\n",
    "    for extensions in point.extensions:\n",
    "        for extension in extensions:\n",
    "            if extension.tag[-5:] == 'speed':\n",
    "                speed.append(float(extension.text))\n",
    "            if extension.tag[-2:] == 'hr':\n",
    "                            hr.append(float(extension.text))\n",
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(15,15))\n",
    "\n",
    "axs[0][0].semilogy(lon, lat)\n",
    "axs[0][0].set_xlabel('longitude')\n",
    "axs[0][0].set_ylabel('latitude')\n",
    "axs[0][0].set_title('Route of the file {}'.format(file))\n",
    "try:\n",
    "    axs[0][1].semilogy(range(0, len(points)), height)\n",
    "    axs[0][1].set_xlabel('number of points')\n",
    "    axs[0][1].set_ylabel('height in m')\n",
    "    axs[0][1].set_title('height-info of the file {}'.format(file))\n",
    "except:\n",
    "    print(\"this file doesn't contain any height data\")\n",
    "try:\n",
    "    axs[1][0].semilogy(range(0, len(points)), speed)\n",
    "    axs[1][0].set_xlabel('number of points')\n",
    "    axs[1][0].set_ylabel('speed in km/u')\n",
    "    axs[1][0].set_title('speed data of the file {}'.format(file))\n",
    "except:\n",
    "    print(\"this file doesn't contain any speed data\")\n",
    "try:\n",
    "    axs[1][1].semilogy(range(0, len(points)), hr)\n",
    "    axs[1][1].set_xlabel('number of points')\n",
    "    axs[1][1].set_ylabel('Heart rate in bpm')\n",
    "    axs[1][1].set_title('Heart rate data of the file {}'.format(file))\n",
    "except:\n",
    "    print(\"this file doesn't contain any heart rate data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simplifying the route\n",
    "\n",
    "We can simplify the route using a point-reduction algorithm. This is the algorithm used:[Ramer-Douglas-Peucker algorithm](<http://en.wikipedia.org/wiki/Ramer-Douglas-Peucker_algorithm>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleGpx = copy(gpx)\n",
    "simpleGpx.tracks[0].segments[0].simplify()\n",
    "smoothLon = []\n",
    "smoothLat = []\n",
    "\n",
    "for punt in simpleGpx.tracks[0].segments[0].points:\n",
    "    smoothLon.append(punt.longitude)\n",
    "    smoothLat.append(punt.latitude)\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(16,8))\n",
    "axs[0].semilogy(lon, lat)\n",
    "axs[0].scatter(lon, lat, c='r')\n",
    "axs[0].set_title('original points in route')\n",
    "axs[1].semilogy(smoothLon, smoothLat)\n",
    "axs[1].scatter(smoothLon, smoothLat, c='r')\n",
    "axs[1].set_title('simplified points in route')\n",
    "axs[0].set_xlabel('longitude')\n",
    "axs[0].set_ylabel('latitude')\n",
    "axs[1].set_xlabel('longitude')\n",
    "axs[1].set_ylabel('latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comparing more random files\n",
    "\n",
    "In the cell below we compare some random files. You can change the number of files used by changing the variable `numberOfFilesUsed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfFilesUsed = 8\n",
    "numberOfPoints = 0\n",
    "time = 0\n",
    "heightInfo = 0\n",
    "timeInfo = 0\n",
    "\n",
    "for randomFile in range(numberOfFilesUsed):\n",
    "    rand = random.randrange(len(filteredData)-1)\n",
    "    file = filteredData[\"filename\"][rand]\n",
    "    gpx_file = open(dataPath + file, 'r')\n",
    "    gpx = gpxpy.parse(gpx_file)\n",
    "    time += gpx.get_duration()\n",
    "    heightInfo += gpx.has_elevations()\n",
    "    timeInfo += gpx.has_times()\n",
    "    numberOfPoints += gpx.tracks[0].segments[0].get_points_no()\n",
    "                \n",
    "print(\"\\nnumber of files analyzed: \" + str(numberOfFilesUsed))\n",
    "print(\"average time in a route: {} seconds\".format(time/numberOfFilesUsed))\n",
    "print(\"number of files with height info:\", heightInfo)\n",
    "print(\"number of files with time info: \", timeInfo)\n",
    "print(\"average number of points in a file: \" + str(numberOfPoints/numberOfFilesUsed) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### info\n",
    "\n",
    "below some charts about how the data is divided across the files.\n",
    "\n",
    "#### representative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ('representative data', 'not-representative data')\n",
    "numbers = (len(filteredData), numberOfFiles-len(filteredData))\n",
    "\n",
    "plt.bar(labels, numbers)\n",
    "plt.ylabel('number of files')\n",
    "plt.title('filtered data')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Height data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfFilesWithHeight = 0\n",
    "\n",
    "for file in filteredData[\"has height\"]:\n",
    "    if file == 1:\n",
    "        numberOfFilesWithHeight += 1\n",
    "        \n",
    "print('there are ' + str(numberOfFilesWithHeight) + ' files with height data out of {} files'.format(len(filteredData)))\n",
    "print('that\\'s ' + str(numberOfFilesWithHeight/len(filteredData)*100) + '%')\n",
    "\n",
    "labels = ('files with height data', 'files without height data')\n",
    "numbers = (numberOfFilesWithHeight, (len(filteredData)-numberOfFilesWithHeight))\n",
    "y = labels\n",
    "\n",
    "plt.bar(y, numbers)\n",
    "plt.ylabel('number of files')\n",
    "plt.title('number of files with height vs without height')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heart rate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfFilesWithHeartRate = 0\n",
    "\n",
    "for file in filteredData[\"has heartbeat\"]:\n",
    "    if file > 0:\n",
    "        numberOfFilesWithHeartRate += 1\n",
    "        \n",
    "print('there\\'s {} files with height data on {} files'.format(numberOfFilesWithHeartRate,len(filteredData)))\n",
    "print('that\\'s {:.2f}%'.format(numberOfFilesWithHeartRate/len(filteredData)*100))\n",
    "\n",
    "labels = ('files with heart rate', 'files without heart rate')\n",
    "numbers = (numberOfFilesWithHeartRate, (len(filteredData)-numberOfFilesWithHeartRate))\n",
    "y = labels\n",
    "\n",
    "plt.bar(y, numbers)\n",
    "plt.xticks(y, labels)\n",
    "plt.ylabel('number of files')\n",
    "plt.title('number of files with heart rate vs without heart rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of the target\n",
    "\n",
    "In this example we'll take the type of the route as target. This means that we'll make models to guess the type of the route by calculating other features. In the cells below is a study on available types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### possible types\n",
    "\n",
    "In the `routeTypes.txt` file in the example folder `datapath` we have a list of possible types and their meaning. Below is a rough print of the first 10 types in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "types = pd.DataFrame(data=pd.read_csv(dataPath + \"/routeTypes.txt\", sep='\\t', index_col=0))\n",
    "types.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of files for each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(filteredData['type'])\n",
    "\n",
    "labels = [types.type[int(label)] for label in counts]\n",
    "figure(num=None, figsize=(6, 10), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.pie([float(value) for value in counts.values()],\n",
    "        labels=[str(value) + ' files' for value in counts.values()],\n",
    "        autopct='%1.2f%%', colors='bgrcmy')\n",
    "plt.title(\"types in original data\")\n",
    "plt.legend(labels, loc='upper center', bbox_to_anchor=(1.45, 0.8), shadow=True, ncol=1)\n",
    "plt.show()\n",
    "\n",
    "print('here\\'s another barchart:')\n",
    "figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "bars = plt.bar(labels, counts.values(), color='bgrcmy')\n",
    "for bar in bars:\n",
    "    yVal = bar.get_height()\n",
    "    plt.text(bar.get_x() + 0.1, yVal, str(yVal) + ' files')\n",
    "plt.title(\"number of files per type\")\n",
    "plt.xlabel(\"type\")\n",
    "plt.ylabel('number of files')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this chart we can clearly see that not all types of the `routeTypes.txt` file are used. These types shouldn't be calculated and ignored, in the line of code below we filter out the types which aren't used and print only the used types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types['type'][[key for key in Counter(filteredData['type']).keys()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Deciding on features and calculating them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Motivation on features\n",
    "\n",
    "Here I've written some info on why features are (not) used\n",
    "\n",
    "### used features:\n",
    "\n",
    " - **Total distance**: This is an easy to calculate feature. The gpxpy library does this for us. It's also a very important one since a type can be highly dependant on distance. For example; a pedestrian won't take a route as long as a car.\n",
    " - **Total time**: This feature is also calculated inside of the gpxpy feature. It's also a golden combo with the total distance.\n",
    " - **Top speed**: Top speed is also a function of the gpxpy library. It's a good feature since speed can give a lot of info about the vehicle used in the route.\n",
    " - **minimal speed**: The lowest speed possible is a usable feature, but can be 0 in a lot of cases. It's also highly correlating with other speed features. Nevertheless it can be important.\n",
    " - **minimal height**: This feature takes the lowest of all heights if there are any. Can be useful because speed and elevation are highly defining on a type.\n",
    " - **Total elevation**: Total elevation is also a function of the gpxpy library.\n",
    " - **average heart rate**: This function is only relevant in routes that contain this information. Probably is this a irrelevant function across all files because of the number of files that contain this data.\n",
    " - **total number of heartbeats**: This feature is highly correlating with other heart rate features, but still can be defining.\n",
    " - **average distance between 2 points**: average distance between two points in the route file. \n",
    " - **Distance between the first and last point**: This is a feature I calculated myself. It can be useful to check if the route is circular or not.\n",
    " - **average number of points per kilometer**: speaks for itself.\n",
    " - **month of the track**: This feature I calculated myself. It can be very useful to define the type since a pedestrian or biker won't go out as often in winter as a driver.\n",
    " - **season**: This is a highly correlating feature with the month of a track, but this feature divides the year in 4 parts.\n",
    " - **starting-hour of the track**: This is a feature of the gpxpy library. It can be useful to check which types prefer morning or evening.\n",
    " - **Maximal heartbeat**: This feature checks for the highest heart rate in the file, but only 1/3rd of the files in the sample data contain heart rate data.\n",
    " - **Meridian of speed**: This feature checks all speeds of every point and calculates the meridian of all speeds.\n",
    " - **Standard deviation of speed**: This feature calculates the standard deviation of the speed, more info on how this works at [Standard deviation on wikipedia](<https://en.wikipedia.org/wiki/Standard_deviation>)\n",
    " - **Has cadence**: This extension can give the number of steps per minute. This can be a very good feature since it can give a very good clue on which type the route represents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculating features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code to calculate features (except for features provided by the gpxpy-library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def is_weekend(gpx):\n",
    "    return 1 if gpx.points[0].time.weekday() >= 5 else 0\n",
    "\n",
    "def get_low_speed(gpx):\n",
    "    top_speed = gpx.get_moving_data().max_speed\n",
    "    for i in range(len(gpx.points)-1):\n",
    "        point = gpx.points[i]\n",
    "        speed = point.speed_between(gpx.points[i + 1])\n",
    "        if speed is None:\n",
    "            return 0\n",
    "        elif speed < top_speed:\n",
    "            top_speed = speed\n",
    "            \n",
    "    return top_speed\n",
    "\n",
    "def get_meridian_speed(gpx):\n",
    "    speed = []\n",
    "    for i in range(len(gpx.points)-1):\n",
    "        point = gpx.points[i]\n",
    "        speed.append(point.speed_between(gpx.points[i + 1]))\n",
    "    try:\n",
    "        return statistics.median(speed)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def get_average_speed(gpx):\n",
    "    n = len(gpx.points)\n",
    "    speeds = []\n",
    "    speed = 0\n",
    "    \n",
    "    for i in range(len(gpx.points)-1):\n",
    "        point = gpx.points[i]\n",
    "        temp_speed = point.speed_between(gpx.points[i + 1])\n",
    "        if temp_speed is not None:\n",
    "            speeds.append(point.speed_between(gpx.points[i + 1]))\n",
    "            speed += point.speed_between(gpx.points[i + 1])\n",
    "        else:\n",
    "            n -= 1\n",
    "    \n",
    "    return speed / n\n",
    "    \n",
    "def get_deviation(gpx):\n",
    "    n = len(gpx.points)\n",
    "    speeds = []\n",
    "    speed = 0\n",
    "    variation = []\n",
    "    variationNumber = 0\n",
    "    \n",
    "    for i in range(len(gpx.points)-1):\n",
    "        point = gpx.points[i]\n",
    "        temp_speed = point.speed_between(gpx.points[i + 1])\n",
    "        if temp_speed is not None:\n",
    "            speeds.append(point.speed_between(gpx.points[i + 1]))\n",
    "            speed += point.speed_between(gpx.points[i + 1])\n",
    "        else:\n",
    "            n -= 1\n",
    "    \n",
    "    average = speed / n\n",
    "    \n",
    "    for speed in speeds:\n",
    "        variation.append((speed - average)**2)\n",
    "        \n",
    "    for number in variation:\n",
    "        variationNumber += number\n",
    "        \n",
    "    return variationNumber / (n-1)\n",
    "\n",
    "def get_high_bpm(gpx):\n",
    "    hr = 0\n",
    "    for punt in gpx.points:\n",
    "        for extensions in punt.extensions:\n",
    "            for extension in extensions:\n",
    "                if extension.tag[-2:] == 'hr':\n",
    "                    if float(extension.text) > hr:\n",
    "                        hr = float(extension.text)\n",
    "    return hr\n",
    "\n",
    "def get_low_bpm(gpx):\n",
    "    hr = get_high_bpm(gpx)\n",
    "    for punt in gpx.points:\n",
    "        for extensions in punt.extensions:\n",
    "            for extension in extensions:\n",
    "                if extension.tag[-2:] == 'hr':\n",
    "                    if float(extension.text) < hr:\n",
    "                        hr = float(extension.text)\n",
    "    return hr\n",
    "\n",
    "def points_per_min(gpx):\n",
    "    points = len(gpx.points)\n",
    "    time = gpx.get_duration()\n",
    "    if time is None or time == 0:\n",
    "        return 0\n",
    "    return points / time\n",
    "\n",
    "def get_average_distance_between_points(gpx):\n",
    "    distance = gpx.length_3d()\n",
    "    return distance / gpx.get_points_no()\n",
    "\n",
    "def get_start_to_end_distance(gpx):\n",
    "    first_point = gpx.points[0]\n",
    "    second_point = gpx.points[len(gpx.points)-1]\n",
    "    distance = first_point.course_between(second_point)\n",
    "    return distance\n",
    "\n",
    "def has_cadence(gpx):\n",
    "    found_cad = 0\n",
    "    for extensions in gpx.points[0].extensions:\n",
    "        for extension in extensions:\n",
    "            if extension.tag[-3:] == 'cad':\n",
    "                found_cad = 1\n",
    "                break\n",
    "    return found_cad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Careful** These calculations can take some time to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = pd.DataFrame()\n",
    "\n",
    "for index, row in filteredData.iterrows():\n",
    "    file = '{}_{}.gpx'.format(int(row['file_id']),int(row['type']))\n",
    "    gpx_file = open(dataPath + file, 'r')\n",
    "    gpx = gpxpy.parse(gpx_file)\n",
    "    track = gpx.tracks[0].segments[0]\n",
    "\n",
    "    features = features.append({\n",
    "            \"total distance\": track.length_3d(),\n",
    "            \"total time\": track.get_duration(),\n",
    "            \"type\": row[\"type\"],\n",
    "            \"top speed\": track.get_moving_data().max_speed,\n",
    "            \"min speed\": get_low_speed(track),\n",
    "            \"min elevation\": track.get_elevation_extremes().minimum if track.get_elevation_extremes().minimum is not None else 0,\n",
    "            \"total elevation\": track.get_uphill_downhill().uphill,\n",
    "            \"average distance between 2 points\": get_average_speed(track),\n",
    "            \"distance between first and last point\": get_start_to_end_distance(track),\n",
    "            \"average points per minute\": points_per_min(track),\n",
    "            \"month\": str(track.get_time_bounds().start_time.month),\n",
    "            \"season\": str(int(track.get_time_bounds().start_time.month / 4)),\n",
    "            \"starting hour\": str(track.get_time_bounds().start_time.hour),\n",
    "            \"isWeekend\": is_weekend(track),\n",
    "            \"max heart rate\": get_high_bpm(track),\n",
    "            \"meridian of speed\": get_meridian_speed(track),\n",
    "            \"standard deviation in speed\": get_deviation(track),\n",
    "            \"has cadence\": has_cadence(track),\n",
    "            \"max elevation\": track.get_elevation_extremes().maximum if track.get_elevation_extremes().maximum is not None else 0,\n",
    "            \"min heart rate\": get_low_bpm(track),\n",
    "            \"average speed\": get_average_speed(track),\n",
    "        }, ignore_index=True)\n",
    "    \n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving features as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv('featuresTest.csv') if useTestData else features.to_csv('features.csv')\n",
    "print('saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature evaluation and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Reading features from csv-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features = pd.read_csv('featuresTest.csv') if useTestData else pd.read_csv('features.csv')\n",
    "features = features.drop(['Unnamed: 0'], axis=1)\n",
    "print('features read!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## taking a look at the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlationMatrix = features.drop(['type'], axis=1).corr()\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.title('correlation matrix features')\n",
    "seaborn.heatmap(correlationMatrix, annot=True, cmap=\"RdBu_r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Constructing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## setting up data/features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y = features['type'].to_numpy().astype(int)\n",
    "X = features.drop(['type'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=40, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of data:\", X.shape)\n",
    "print(\"Shape of target:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"number of features:\", X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Selecting a model\n",
    "\n",
    "Why to use a specific model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### KNN-model\n",
    "\n",
    "KNN is the simplest model. It memorises the training-data and puts the to-predict data on the same chart. For each to predict target, it searches the nearest training point and sets the target value to the same as the neighbour. You can choose how many neighbours the model should include to give a value to the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree model\n",
    "\n",
    "A decision tree model can be very detailed, because of all the steps and decisions it takes, this can take more time than a KNN or Linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. model evaluation and comparing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Building models and taking a look\n",
    "\n",
    "Below we start building models and take a quick look at them without parameter tuning.\n",
    "\n",
    "### looking at the data\n",
    "\n",
    "Taking a quick look at the data is very handy. We can see how each type is divided across the features, so we can select the best performing models to start parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = [types.type[int(label)] for label in counts.keys()]\n",
    "plot = pd.plotting.scatter_matrix(X, c=y, label=labels, figsize=(16, 10), marker='o', hist_kwds={'bins': 1})\n",
    "plt.legend(labels, loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using a KNN-model to define type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainingScore = []\n",
    "testScore = []\n",
    "\n",
    "for n in range(1, neighbors+1):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n).fit(X_train,y_train)\n",
    "    \n",
    "    trainingScore.append(round(knn.score(X_train,y_train) * 100, 2))\n",
    "    testScore.append(round(knn.score(X_test,y_test) * 100, 2))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16, 5))\n",
    "objects = range(1, neighbors+1)\n",
    "\n",
    "ax1.bar(objects, trainingScore, align='center')\n",
    "ax1.set_title('training score on ' + str(len(X)) + ' files')\n",
    "ax1.set_ylabel('percentage right (%)')\n",
    "ax1.set_xlabel('number of neighbors')\n",
    "\n",
    "ax2.bar(objects, testScore, align='center')\n",
    "ax2.set_ylim(0, 100)\n",
    "ax2.set_title('test score on ' + str(len(X)) + ' files')\n",
    "ax2.set_ylabel('percentage right (%)')\n",
    "ax2.set_xlabel('number of neighbors')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16, 5))\n",
    "ax1.plot(objects, trainingScore)\n",
    "ax1.set_title('enlarged scale impact per depth in training')\n",
    "ax1.set_ylabel('percentage right (%)')\n",
    "ax1.set_xlabel('number of neighbors')\n",
    "\n",
    "ax2.plot(objects, testScore)\n",
    "ax2.set_title('enlarged scale impact per depth in test')\n",
    "ax2.set_ylabel('percentage right (%)')\n",
    "ax2.set_xlabel('number of neighbors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### using decision tree classifier to define type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainingScore = []\n",
    "testScore = []\n",
    "\n",
    "for n in range(1, depth+1):\n",
    "    treeModel = DecisionTreeClassifier(max_depth=n, random_state=42).fit(X_train, y_train)\n",
    "    \n",
    "    trainingScore.append(round(treeModel.score(X_train,y_train) * 100, 2))\n",
    "    testScore.append(round(treeModel.score(X_test,y_test) * 100, 2))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16, 5))\n",
    "objects = range(1, depth+1)\n",
    "\n",
    "ax1.bar(objects, trainingScore, align='center')\n",
    "ax1.set_title('trainingScore on ' + str(len(X)) + ' files')\n",
    "ax1.set_ylabel('percentage right (%)')\n",
    "ax1.set_xlabel('depth')\n",
    "\n",
    "ax2.bar(objects, testScore, align='center')\n",
    "ax2.set_ylim(0, 100)\n",
    "ax2.set_title('testScore on ' + str(len(X)) + ' files')\n",
    "ax2.set_ylabel('percentage right (%)')\n",
    "ax2.set_xlabel('depth')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16, 5))\n",
    "ax1.plot(objects, trainingScore)\n",
    "ax1.set_title('enlarged scale impact per depth in in test')\n",
    "ax1.set_ylabel('percentage right (%)')\n",
    "ax1.set_xlabel('depth')\n",
    "\n",
    "ax2.plot(objects, testScore)\n",
    "ax2.set_title('enlarged scale impact per depth in test')\n",
    "ax2.set_ylabel('percentage right (%)')\n",
    "ax2.set_xlabel('depth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### using random forest classifier to define type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingScore = []\n",
    "testScore = []\n",
    "\n",
    "for n in range(1, depth+1):\n",
    "    clf = RandomForestClassifier(n_estimators=n).fit(X_train,y_train)\n",
    "    \n",
    "    trainingScore.append(round(clf.score(X_train,y_train) * 100, 2))\n",
    "    testScore.append(round(clf.score(X_test,y_test) * 100, 2))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16, 5))\n",
    "objects = range(1, depth+1)\n",
    "\n",
    "ax1.bar(objects, trainingScore, align='center')\n",
    "ax1.set_title('trainingScore on ' + str(len(X)) + ' files')\n",
    "ax1.set_ylabel('percentage right (%)')\n",
    "ax1.set_xlabel('number of estimators')\n",
    "\n",
    "ax2.bar(objects, testScore, align='center')\n",
    "ax2.set_ylim(0, 100)\n",
    "ax2.set_title('testScore on ' + str(len(X)) + ' files')\n",
    "ax2.set_ylabel('percentage right (%)')\n",
    "ax2.set_xlabel('number of estimators')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16, 5))\n",
    "ax1.plot(objects, trainingScore)\n",
    "ax1.set_title('enlarged scale per depth in training')\n",
    "ax1.set_ylabel('percentage right (%)')\n",
    "ax1.set_xlabel('number of estimators')\n",
    "\n",
    "ax2.plot(objects, testScore)\n",
    "ax2.set_title('enlarged scale per depth in training')\n",
    "ax2.set_ylabel('percentage right (%)')\n",
    "ax2.set_xlabel('number of estimators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting classifier to define type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainingScore = []\n",
    "testScore = []\n",
    "\n",
    "depth = 10\n",
    "\n",
    "for n in range(1, depth+1):\n",
    "    gbrt = GradientBoostingClassifier(random_state=42, max_depth=n).fit(X_train, y_train)\n",
    "    \n",
    "    trainingScore.append(round(gbrt.score(X_train,y_train) * 100, 2))\n",
    "    testScore.append(round(gbrt.score(X_test,y_test) * 100, 2))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16, 5))\n",
    "objects = range(1, depth+1)\n",
    "\n",
    "ax1.bar(objects, trainingScore)\n",
    "ax1.set_title('trainingScore on ' + str(len(X)) + ' files')\n",
    "ax1.set_ylabel('percentage right (%)')\n",
    "ax1.set_xlabel('depth ')\n",
    "\n",
    "ax2.bar(objects, testScore, align='center')\n",
    "ax2.set_ylim(0, 100)\n",
    "ax2.set_title('testScore on ' + str(len(X)) + ' files')\n",
    "ax2.set_ylabel('percentage right (%)')\n",
    "ax2.set_xlabel('depth')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16, 5))\n",
    "ax1.plot(objects, trainingScore)\n",
    "ax1.set_title('enlarged scale per depth in training')\n",
    "ax1.set_ylabel('percentage right (%)')\n",
    "ax1.set_xlabel('depth')\n",
    "\n",
    "ax2.plot(objects, testScore)\n",
    "ax2.set_title('enlarged impact per depth in test')\n",
    "ax2.set_ylabel('percentage right (%)')\n",
    "ax2.set_xlabel('depth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### logistic regression to define type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logisticRegr = LogisticRegression(solver='liblinear', multi_class = 'auto')\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "\n",
    "print('training score: ',round(logisticRegr.score(X_train,y_train) * 100, 2))\n",
    "print('test score: ', round(logisticRegr.score(X_test,y_test) * 100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## tuning the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kFold = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5).fit(X_train, y_train)\n",
    "\n",
    "res_df = pd.DataFrame(cross_validate(knn, X, y, cv=kFold, return_train_score=True))\n",
    "scores = cross_val_score(knn, X, y)\n",
    "\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "res_df = pd.DataFrame(cross_validate(lr, X, y, cv=kFold, return_train_score=True))\n",
    "scores = cross_val_score(lr, X, y)\n",
    "\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=5, random_state=42).fit(X_train, y_train)\n",
    "\n",
    "res_df = pd.DataFrame(cross_validate(tree, X, y, cv=kFold, return_train_score=True))\n",
    "scores = cross_val_score(tree, X, y)\n",
    "\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))\n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Grid Search\n",
    "\n",
    "Below we divide the data into a test-set, training-set and a validation set. These will be used to figure out which is the best model. After these steps, we use grid search to better the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_validation, X_test, y_train_validation, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_validation, y_train_validation, random_state=42)\n",
    "\n",
    "print(\"Size of training set: {}   size of validation set: {}   size of test set:\"\n",
    "      \" {}\\n\".format(X_train.shape[0], X_valid.shape[0], X_test.shape[0]))\n",
    "\n",
    "topScore = 0\n",
    "bm = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### GridSearch in KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "best_parameters = 0\n",
    "\n",
    "for n in range(1, 11):\n",
    "        knn = KNeighborsClassifier(n_neighbors = n).fit(X_train, y_train)\n",
    "        score = knn.score(X_valid, y_valid)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'n_neighbors': n}\n",
    "            if score > topScore:\n",
    "                topScore = score\n",
    "                bm = knn\n",
    "\n",
    "print(\"Best parameters: \", best_parameters)\n",
    "\n",
    "knn = KNeighborsClassifier(**best_parameters).fit(X_train_validation, y_train_validation)\n",
    "training_score = knn.score(X_train, y_train)\n",
    "test_score = knn.score(X_test, y_test)\n",
    "\n",
    "print(\"\\nTraining set score with best parameters : {:.2f}\".format(training_score))\n",
    "print(\"Best score on validation set: {:.2f}\".format(best_score))\n",
    "print(\"Test set score with best parameters: {:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### GridSearch in Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "\n",
    "for depth in range(1, 15):\n",
    "    for rs in [0,5,10,20,42]:\n",
    "        tree = DecisionTreeClassifier(max_depth=depth, random_state=rs)\n",
    "        tree.fit(X_train, y_train)\n",
    "        score = tree.score(X_valid, y_valid)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'max_depth': depth, 'random_state': rs}\n",
    "            if score > topScore:\n",
    "                topScore = score\n",
    "                bm = tree\n",
    "\n",
    "print(\"Best parameters: \", best_parameters)\n",
    "\n",
    "tree = DecisionTreeClassifier(**best_parameters)\n",
    "tree.fit(X_train_validation, y_train_validation)\n",
    "training_score = tree.score(X_train, y_train)\n",
    "test_score = tree.score(X_test, y_test)\n",
    "\n",
    "print(\"\\nTraining set score with best parameters : {:.2f}\".format(training_score))\n",
    "print(\"Best score on validation set: {:.2f}\".format(best_score))\n",
    "print(\"Test set score with best parameters: {:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### gridSearch in Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "\n",
    "for n in range(1, 50):\n",
    "    for rs in [0,5,10,20,42]:\n",
    "        rfc = RandomForestClassifier(n_estimators=n, random_state=rs).fit(X_train, y_train)\n",
    "        score = rfc.score(X_valid, y_valid)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'n_estimators': n, 'random_state':rs}\n",
    "            if score > topScore:\n",
    "                topScore = score\n",
    "                bm = rfc\n",
    "\n",
    "print(\"Best parameters: \", best_parameters)\n",
    "\n",
    "rfc = RandomForestClassifier(**best_parameters).fit(X_train_validation, y_train_validation)\n",
    "training_score = rfc.score(X_train, y_train)\n",
    "test_score = rfc.score(X_test, y_test)\n",
    "\n",
    "print(\"\\nTraining set score with best parameters : {:.2f}\".format(training_score))\n",
    "print(\"Best score on validation set: {:.2f}\".format(best_score))\n",
    "print(\"Test set score with best parameters: {:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### gridSearch in Gradient Boosted Regression Trees\n",
    "\n",
    "**careful** These calculations can take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "\n",
    "for n in range(1, 15):\n",
    "        for rs in [0,5,10,20,42]:\n",
    "            gbrt = GradientBoostingClassifier(random_state=rs, max_depth=n).fit(X_train, y_train)\n",
    "            score = gbrt.score(X_valid, y_valid)\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_parameters = {'max_depth': n, 'random_state': rs}\n",
    "                if score > topScore:\n",
    "                    topScore = score\n",
    "                    bm = gbrt\n",
    "\n",
    "print(\"Best parameters: \", best_parameters)\n",
    "\n",
    "gbrt = RandomForestClassifier(**best_parameters).fit(X_train_validation, y_train_validation)\n",
    "training_score = gbrt.score(X_train, y_train)\n",
    "test_score = gbrt.score(X_test, y_test)\n",
    "\n",
    "print(\"\\nTraining set score with best parameters : {:.2f}\".format(training_score))\n",
    "print(\"Best score on validation set: {:.2f}\".format(best_score))\n",
    "print(\"Test set score with best parameters: {:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Best Model\n",
    "\n",
    "Below is a printout of the best performing model, which is automatically selected based on the best test score. Further is also shown how the model relates into graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_score = bm.score(X_train, y_train)\n",
    "test_score = bm.score(X_test, y_test)\n",
    "print(\"best model:\", bm)\n",
    "print(\"\\nTraining set score with best parameters : {:.2f}\".format(training_score))\n",
    "print(\"Best score on validation set: {:.2f}\".format(best_score))\n",
    "print(\"Test set score with best parameters: {:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here's a graph on what features makes the biggest difference and are the most important to out model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def feature_importance(model):\n",
    "    n_features = X.shape[1]\n",
    "    plt.barh(np.arange(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), X)\n",
    "    plt.title('Importance of features in model')\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.ylim(-1, n_features)\n",
    "\n",
    "feature_importance(bm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Below the predicted data and original data is put into a dataframe to later use in charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = bm.predict(X)\n",
    "originalCount = Counter(y)\n",
    "counts = Counter(results)\n",
    "types = pd.DataFrame(data=pd.read_csv(dataPath + \"/routeTypes.txt\", sep='\\t', index_col=0))\n",
    "\n",
    "originalFrame = pd.DataFrame(dtype=int)\n",
    "\n",
    "for result in originalCount:\n",
    "    originalFrame = originalFrame.append({\n",
    "       'type': result,\n",
    "       'count': originalCount[result]\n",
    "    }, ignore_index = True)\n",
    "\n",
    "resultsFrame = pd.DataFrame(dtype=int)\n",
    "\n",
    "for result in counts:\n",
    "    resultsFrame = resultsFrame.append({\n",
    "       'type': result,\n",
    "       'count': counts[result]\n",
    "    }, ignore_index = True)\n",
    "\n",
    "originalFrame = originalFrame.sort_values('type')\n",
    "resultsFrame = resultsFrame.sort_values('type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## comparing original data vs predicted data\n",
    "\n",
    "Below we display our final results from our best model. We can see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,15))\n",
    "labels = originalFrame['type']\n",
    "ax1.pie(originalFrame['count'],\n",
    "        labels=['{} files'.format(int(value)) for value in originalFrame['count']],\n",
    "        autopct='%1.2f%%', colors='bgrcmy')\n",
    "ax2.legend(labels, loc='upper center', bbox_to_anchor=(1.45, 0.8), shadow=True, ncol=1)\n",
    "ax1.set_title(\"types in original data\")\n",
    "\n",
    "labels = [types.type[int(label)] for label in resultsFrame['type']]\n",
    "ax2.pie(resultsFrame['count'],\n",
    "        labels=['{} files'.format(int(value)) for value in resultsFrame['count']],\n",
    "        autopct='%1.2f%%', colors='bgrcmy')\n",
    "ax2.legend(labels, loc='upper center', bbox_to_anchor=(1.45, 0.8), shadow=True, ncol=1)\n",
    "ax2.set_title(\"types in predicted data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('here\\'s another barchart comparing the original barchart')\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(20,8))\n",
    "\n",
    "labels = [types.type[int(label)] for label in originalFrame['type']]\n",
    "bars = ax1.bar(labels, originalFrame['count'], color='bgrcmy')\n",
    "for bar in bars:\n",
    "    yVal = bar.get_height()\n",
    "    ax1.text(bar.get_x() + 0.1, yVal, str(yVal) + ' files')\n",
    "ax1.set_title(\"types in original data\")\n",
    "ax1.set_ylabel('number of files')\n",
    "ax1.set_xlabel('types')\n",
    "\n",
    "labels = [types.type[int(label)] for label in resultsFrame['type']]\n",
    "bars = ax2.bar(labels, resultsFrame['count'], color='bgrcmy')\n",
    "for bar in bars:\n",
    "    yVal = bar.get_height()\n",
    "    ax2.text(bar.get_x() + 0.1, yVal, str(yVal) + ' files')\n",
    "ax2.set_title(\"types in predicted data\")\n",
    "ax2.set_ylabel('number of files')\n",
    "ax2.set_xlabel('types')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "width =0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,4))\n",
    "\n",
    "ax.bar(np.arange(len(originalFrame['type'])), originalFrame['count'], width=width)\n",
    "ax.bar(np.arange(len(resultsFrame['type']))+ width, resultsFrame['count'], width=width)\n",
    "ax.set_xlabel('type')\n",
    "ax.set_xticks(np.arange(len(originalFrame['type'])))\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylabel('number of files')\n",
    "ax.legend([\"original types\", \"predicted types\"])\n",
    "ax.set_title('original types vs predicted types')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# resolution\n",
    "\n",
    "The predicted data clearly shows that the decision trees with tuned parameters ultimately score the best, especially the Random Forest and the Gradient boosted Regression score high. The data seems very well predicted. There is still some confusion between the \"walk\" type and the \"recreational cycling\" type. I eventually corrected this with the addition of the feature \"hasCad\", this feature consists of a binary variable that indicates whether the route contains a cadence. Cadence is expressed in steps per minute, so a cyclist can cycle as slowly as a walker, but will not have a cadence as high. All other features naturally also contribute to the decision tree."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('elian': virtualenv)",
   "language": "python",
   "name": "python_defaultSpec_1597818690161"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}